{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d7c23a-be4c-4ac9-8eb8-67a1925b385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "con = sqlite3.connect(\"JudicialAnalysis.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff7a0d06-6c97-4348-acee-09ff10f60260",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8864568-2b00-4df6-b1f6-80efdb12c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 Table\n",
    "#cur.execute(\"CREATE TABLE results(jid, date, law, keyword_type, keywords)\")\n",
    "#con.commit()\n",
    "#con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0d9113d-5520-48ef-a854-e67d49515db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ElementExtractor import Judicial_Parser\n",
    "import os, time, traceback, json, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412555e-fb92-4e6b-bb67-ca047939695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36b98aa0-12d8-4d23-8f20-4a8152bff0cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1efHsY16pxK0lBD2gYCgCTnv1Swstq771\n",
      "From (redirected): https://drive.google.com/uc?id=1efHsY16pxK0lBD2gYCgCTnv1Swstq771&confirm=t&uuid=06dbc6eb-cbd8-4abe-8206-d345b3ad7aab\n",
      "To: C:\\課程\\交大\\論文\\Code\\data.zip\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1.88G/1.88G [03:01<00:00, 10.3MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Downloads to ./data.zip (2GB) and extracts to ./data/\n",
    "# data_utils.download_data_url(\"./\") # iis-ckip\n",
    "#data_utils.download_data_gdown(\"./\") # gdrive-ckip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "019599b6-28f9-4e35-b8ec-e374a18fef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    }
   ],
   "source": [
    "# To use GPU:\n",
    "#    1. Install tensorflow-gpu (see Installation)\n",
    "#    2. Set CUDA_VISIBLE_DEVICES environment variable, e.g. os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#    3. Set disable_cuda=False, e.g. ws = WS(\"./data\", disable_cuda=False)\n",
    "\n",
    "# 採坑心得\n",
    "# 新版已經沒有 tensorflow-gpu\n",
    "# 我使用 python 3.7 的環境 (conda create -n ckipcore python=3.7)\n",
    "# 先安裝 pip install -U ckiptagger[tf,gdown]\n",
    "# 再改用 Conda install tensorflow 去安裝匹配的新版\n",
    "# 搭配 disable_cuda=False 參數，從 windows 工作管理員之效能頁籤看起來，確實有使用 GPU\n",
    "\n",
    "ws = WS(\"./data\", disable_cuda=False)\n",
    "pos = POS(\"./data\", disable_cuda=False)\n",
    "ner = NER(\"./data\", disable_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c436454-555b-47e8-aa2b-2973cd18849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡繁轉換器 (暫時用不到)\n",
    "# import opencc\n",
    "# converter = opencc.OpenCC('t2s.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ace9c05f-db18-4bf0-985a-6ccefd5ec8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      ">>開始分析...\n",
      "[當前已分析數量] 17096\n",
      "[累計耗時] 8:25:27\n",
      "[當前檔案] C:\\課程\\交大\\論文\\案件整理\\202201\\臺灣士林地方法院刑事\\SLDM,110,聲,1370,20220124,1.json\n",
      "[WS] 分析中\n",
      "[POS] 分析中\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_4236\\1882992868.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m                 )\n\u001b[0;32m     78\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[POS] 分析中'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0mpos_sentence_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_sentence_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[NER] 分析中'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                 \u001b[0mentity_sentence_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_sentence_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_sentence_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, sentence_list, sentence_segmentation, segment_delimiter_set, character_normalization, batch_sentences, batch_characters)\u001b[0m\n\u001b[0;32m    229\u001b[0m                 \u001b[0mparital_pos_segment_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                 \u001b[0mparital_pos_segment_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_label_for_a_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpartial_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m                 \u001b[0mpos_segment_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparital_pos_segment_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpartial_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\model_pos.py\u001b[0m in \u001b[0;36mpredict_label_for_a_batch\u001b[1;34m(self, sample_list)\u001b[0m\n\u001b[0;32m    420\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_v\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    421\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 422\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_v\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    423\u001b[0m             }\n\u001b[0;32m    424\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 969\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    970\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1192\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1193\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1372\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1373\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1360\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1362\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1454\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1456\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'[現在時間] {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "source_file = os.path.join(\n",
    "        'C:\\\\', '課程', '交大','論文','案件整理',\n",
    "        'json_files.txt'\n",
    "        )\n",
    "    \n",
    "count_file_done_num = 0\n",
    "clear_output()\n",
    "print('-'*50)\n",
    "print(f'>>開始分析...')\n",
    "print(f'[當前已分析數量] {count_file_done_num}')\n",
    "\n",
    "with open(source_file, 'r', encoding='utf-8') as f:\n",
    "    # 2022~2023年判決書有211萬7,454個json檔\n",
    "    # 故一次讀一個處理，減少記憶體占用\n",
    "    raw_data = ''\n",
    "    \n",
    "    while 1: \n",
    "        # 開始逐案讀取資料分析\n",
    "        file = f.readline()\n",
    "        count_file_done_num += 1\n",
    "        \n",
    "        if '刑事' in file:\n",
    "            # 篩掉一些比較非刑案的\n",
    "            if not ('簡易' in file or '民事' in file or '補償' in file or '憲法' in file or '商業' in file):\n",
    "                # 開始讀取裁判書內容\n",
    "                file = file.strip()\n",
    "\n",
    "                # 顯示進度\n",
    "                temp_time = time.time()\n",
    "                elapsed_time = temp_time - start_time\n",
    "                hours = int(elapsed_time // 3600)  # 計算小時數\n",
    "                minutes = int((elapsed_time % 3600) // 60)  # 計算分鐘數\n",
    "                seconds = int(elapsed_time % 60)  # 計算剩餘秒數\n",
    "                \n",
    "                clear_output()\n",
    "                print('-'*50)\n",
    "                print(f'>>開始分析...')\n",
    "                print(f'[當前已分析數量] {count_file_done_num}')\n",
    "                print(f'[累計耗時] {hours}:{minutes}:{seconds}')\n",
    "                print(f'[當前檔案] {file}')\n",
    "                \n",
    "                # 確定 file 存在\n",
    "                if not os.path.isfile(file):\n",
    "                    print(f'[並非正常檔案] 跳過...')\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                \n",
    "                with open(file, 'r', encoding='utf-8') as jf:\n",
    "                    json_data = json.load(jf)\n",
    "                \n",
    "                # 資料清洗\n",
    "                parser = Judicial_Parser(json_data)\n",
    "                \n",
    "                jid = parser.jid.strip().replace(' ', '')\n",
    "                date = parser.dateSTR.strip().replace(' ', '')\n",
    "                raw = parser.raw\n",
    "                text = parser.text\n",
    "                text_u = parser.text_u\n",
    "                \n",
    "                # 確定是否已經在資料庫內\n",
    "                check_res = cur.execute(f'SELECT jid FROM results WHERE jid=\"{jid}\"')\n",
    "                temp = check_res.fetchone()\n",
    "                if temp:\n",
    "                    print(f'[JID] {jid}')\n",
    "                    print('>>此JID發現資料庫已有，跳過')\n",
    "                    continue\n",
    "                    \n",
    "                # 沒有在資料庫內才處理\n",
    "                # Input text\n",
    "                print('[WS] 分析中')\n",
    "                sentence_list = text_u.split('。')\n",
    "                word_sentence_list = ws(\n",
    "                    sentence_list,\n",
    "                    # sentence_segmentation = True, # To consider delimiters\n",
    "                    # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}), # This is the defualt set of delimiters\n",
    "                    # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "                    # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "                )\n",
    "                print('[POS] 分析中')\n",
    "                pos_sentence_list = pos(word_sentence_list)\n",
    "                print('[NER] 分析中')\n",
    "                entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "                \n",
    "                # 用 POS 區分的類型\n",
    "                type_dict = dict()\n",
    "                for idx, words in enumerate(word_sentence_list):\n",
    "                    for idx2, w in enumerate(words):\n",
    "                        temp_type = pos_sentence_list[idx][idx2]\n",
    "                        type_dict.setdefault(temp_type, set())\n",
    "                        type_dict[temp_type].add(w)\n",
    "                \n",
    "                # 經人工檢查，N(名詞)比較符合需要的有\n",
    "                # 'Na', 'Nb'\n",
    "                type_N = [t for t in type_dict.keys() if t.startswith('N')]\n",
    "                type_N.sort()\n",
    "                for n in type_N:\n",
    "                    print('-'*50)\n",
    "                    print(f'TYPE: {n}')\n",
    "                    print(type_dict[n])\n",
    "\n",
    "                # 經人工檢查，V(動詞)比較符合需要的有\n",
    "                # 'VA', 'VC', 'VD, 'VH', \n",
    "                type_V = [t for t in type_dict.keys() if t.startswith('V')]\n",
    "                type_V.sort()\n",
    "                for v in type_V:\n",
    "                    print('-'*50)\n",
    "                    print(f'TYPE: {v}')\n",
    "                    print(type_dict[v])\n",
    "                \n",
    "                # 擷取法條\n",
    "                laws = set()\n",
    "                for e in entity_sentence_list:\n",
    "                    for ee in e:\n",
    "                        if ee[2] == 'LAW':\n",
    "                            laws.add(ee[3])\n",
    "                print('-'*50)\n",
    "                print('TYPE: LAW')\n",
    "                print(laws)\n",
    "                \n",
    "                if not laws:\n",
    "                    print('>>此篇未發現 law 犯罪條文，跳過')\n",
    "                    continue\n",
    "                \n",
    "                # 寫入 Table\n",
    "                print('-'*50)\n",
    "                print('>>準備寫入 Table')\n",
    "                # results(jid, date, law, keyword_type, keywords)\n",
    "                \n",
    "                for law in laws:\n",
    "                    # 初步處理一下 law 會\n",
    "                    law = law.strip().replace(' ', '')\n",
    "                    # 先從名詞\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 Na')\n",
    "                    if 'Na' in type_dict:\n",
    "                        na_set = {n.strip().replace(' ', '') for n in type_dict['Na'] if len(n.strip().replace(' ', '')) > 1}\n",
    "                        na_set = [n for n in na_set if n]\n",
    "                        na_set.sort()\n",
    "                        na_strs = ','.join(na_set)\n",
    "                        cur.execute(f\"INSERT INTO results VALUES('{jid}', '{date}', '{law}', 'Na', '{na_strs}')\")\n",
    "                        con.commit()\n",
    "                    \n",
    "                    # 先從名詞\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 Nb')\n",
    "                    if 'Nb' in type_dict:\n",
    "                        na_set = {n.strip().replace(' ', '') for n in type_dict['Nb'] if len(n.strip().replace(' ', '')) > 1}\n",
    "                        na_set = [n for n in na_set if n]\n",
    "                        na_set.sort()\n",
    "                        na_strs = ','.join(na_set)\n",
    "                        cur.execute(f\"INSERT INTO results VALUES('{jid}', '{date}', '{law}', 'Nb', '{na_strs}')\")\n",
    "                        con.commit()\n",
    "                    \n",
    "                    # 再來動詞\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 VA')\n",
    "                    if 'VA' in type_dict:\n",
    "                        na_set = {n.strip().replace(' ', '') for n in type_dict['VA'] if len(n.strip().replace(' ', '')) > 1}\n",
    "                        na_set = [n for n in na_set if n]\n",
    "                        na_set.sort()\n",
    "                        na_strs = ','.join(na_strs)\n",
    "                        cur.execute(f\"INSERT INTO results VALUES('{jid}', '{date}', '{law}', 'VA', '{na_strs}')\")\n",
    "                        con.commit()\n",
    "                    \n",
    "                    # 再來動詞\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 VC')\n",
    "                    if 'VC' in type_dict:\n",
    "                        na_set = {n.strip().replace(' ', '') for n in type_dict['VC'] if len(n.strip().replace(' ', '')) > 1}\n",
    "                        na_set = [n for n in na_set if n]\n",
    "                        na_set.sort()\n",
    "                        na_strs = ','.join(na_set)\n",
    "                        cur.execute(f\"INSERT INTO results VALUES('{jid}', '{date}', '{law}', 'VC', '{na_strs}')\")\n",
    "                        con.commit()\n",
    "                    \n",
    "                    # 再來動詞\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 VD')\n",
    "                    if 'VD' in type_dict:\n",
    "                        na_set = {n.strip().replace(' ', '') for n in type_dict['VD'] if len(n.strip().replace(' ', '')) > 1}\n",
    "                        na_set = [n for n in na_set if n]\n",
    "                        na_set.sort()\n",
    "                        na_strs = ','.join(na_set)\n",
    "                        cur.execute(f\"INSERT INTO results VALUES('{jid}', '{date}', '{law}', 'VD', '{na_strs}')\")\n",
    "                        con.commit()\n",
    "                    \n",
    "                    # 再來動詞\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 VH')\n",
    "                    if 'VH' in type_dict:\n",
    "                        na_set = {n.strip().replace(' ', '') for n in type_dict['VH'] if len(n.strip().replace(' ', '')) > 1}\n",
    "                        na_set = [n for n in na_set if n]\n",
    "                        na_set.sort()\n",
    "                        na_strs = ','.join(na_set)\n",
    "                        cur.execute(f\"INSERT INTO results VALUES('{jid}', '{date}', '{law}', 'VH', '{na_strs}')\")\n",
    "                        con.commit()\n",
    "\n",
    "                    print('-'*50)\n",
    "                    print('>>完成!!!')\n",
    "con.close()\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours = int(elapsed_time // 3600)  # 計算小時數\n",
    "minutes = int((elapsed_time % 3600) // 60)  # 計算分鐘數\n",
    "seconds = int(elapsed_time % 60)  # 計算剩餘秒數\n",
    "print(f'[累計耗時] {hours}:{minutes}:{seconds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0d3f6e-aaa5-4a75-affd-820889c18a06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
