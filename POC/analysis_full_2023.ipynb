{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44d7c23a-be4c-4ac9-8eb8-67a1925b385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "'''\n",
    "一共開 3 個 DB\n",
    "1. 存 NER 結果\n",
    "2. 存 POS 結果\n",
    "3. 存 RE 結果: 含網址、Email、Username、(行動、市內)電話、IP\n",
    "'''\n",
    "\n",
    "con_NER = sqlite3.connect(\"JudicialAnalysis_NER.db\")\n",
    "cur_NER = con_NER.cursor()\n",
    "\n",
    "con_POS = sqlite3.connect(\"JudicialAnalysis_POS.db\")\n",
    "cur_POS = con_POS.cursor()\n",
    "\n",
    "con_RE = sqlite3.connect(\"JudicialAnalysis_RE.db\")\n",
    "cur_RE = con_RE.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8864568-2b00-4df6-b1f6-80efdb12c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 Table\n",
    "new = 0\n",
    "if new:\n",
    "    cur_NER.execute(\"CREATE TABLE results(jid, date, keyword_type, keywords)\")\n",
    "    con_NER.commit()\n",
    "    con_NER.close()\n",
    "    \n",
    "    cur_POS.execute(\"CREATE TABLE results(jid, date,  keyword_type, keywords)\")\n",
    "    con_POS.commit()\n",
    "    con_POS.close()\n",
    "    \n",
    "    cur_RE.execute(\"CREATE TABLE results(jid, date, keyword_type, keywords)\")\n",
    "    con_RE.commit()\n",
    "    con_RE.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27dc84cf-058c-4bd2-a6b5-d35954334f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把原本裁判書檔按順序反過來\n",
    "# 從 2023年12月開始\n",
    "reverse = 0 # 已經做過就不用再做了\n",
    "if reverse:\n",
    "    import os \n",
    "\n",
    "    source_file = os.path.join(\n",
    "            'C:\\\\', '課程', '交大','論文','案件整理',\n",
    "            'json_files.txt'\n",
    "            )\n",
    "\n",
    "    with open(source_file, 'r', encoding='utf-8') as f:\n",
    "        # 2022~2023年判決書有211萬7,454個json檔\n",
    "        # 故一次讀一個處理，減少記憶體占用\n",
    "        json_files_R = f.read().strip().split('\\n')\n",
    "\n",
    "    json_files_R.sort(reverse=True)\n",
    "    json_files_R = [f for f in json_files_R if os.path.isfile(f)]\n",
    "\n",
    "    source_file_R = os.path.join(\n",
    "            'C:\\\\', '課程', '交大','論文','案件整理',\n",
    "            'json_files_R.txt'\n",
    "            )\n",
    "    \n",
    "    json_files_R_STR = '\\n'.join(json_files_R).strip()\n",
    "    \n",
    "    with open(source_file_R, 'w', encoding='utf-8') as f:\n",
    "        # 2022~2023年判決書有211萬7,454個json檔\n",
    "        # 故一次讀一個處理，減少記憶體占用\n",
    "        f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c12b4e2-c1ad-467e-8d08-af2606cd0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from valid_IP import valid_IPv4s, valid_IPv6s\n",
    "\n",
    "# 用來抓網址s、Domains\n",
    "def extract_urls(text):\n",
    "    urls = []\n",
    "    patterns = [r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', r'https?://([\\w\\.\\-]+)']\n",
    "    for url_pattern in patterns:\n",
    "        urls += re.findall(url_pattern, text)\n",
    "    urls = list(set(urls))\n",
    "    urls.sort()\n",
    "    return urls\n",
    "\n",
    "# 用來抓 Emails\n",
    "def extract_emails(text):\n",
    "    email_pattern = r'[\\w.-]+@[\\w.-]+'\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    emails = list(set(emails))\n",
    "    emails.sort()\n",
    "    return emails\n",
    "\n",
    "# 用來抓 Usernames\n",
    "# \\w : 包括(alphanumeric) [0-9a-zA-Z_]\n",
    "# 後來發現 \\w 在 python3 是 unicode 也支持中文\n",
    "# 解決方法: 要在 re.findall 第三個參數加入 re.A 恢復使用 ASCII，例如: re.findall(r\"\\w\", text, re.A))\n",
    "# 我是乾脆直接指定 [0-9a-zA-Z_]\n",
    "def extract_usernames(text):\n",
    "    # 用戶名模式：開頭可能有@，接著是字母、數字、下劃線、點或破折號\n",
    "    username_pattern = r'@?[a-zA-Z][0-9a-zA-Z_.-]+'\n",
    "    usernames = re.findall(username_pattern, text)\n",
    "    usernames = list(set(usernames))\n",
    "    usernames.sort()\n",
    "    return usernames\n",
    "\n",
    "# 用來抓手機號碼\n",
    "def extract_mobilephones(text):\n",
    "    # 手機可能有 - 也可能沒有 -\n",
    "    # 國際號碼可能有 886\n",
    "    cellphones = []\n",
    "    cellphone_patterns = [r'(\\+?886\\d{3}-?\\d{3}-?\\d{3})', r'(0\\d{3}-?\\d{3}-?\\d{3})']\n",
    "    for cellphone_pattern in cellphone_patterns:\n",
    "        cellphones += re.findall(cellphone_pattern, text)\n",
    "    cellphones = list(set(cellphones))\n",
    "    cellphones.sort()\n",
    "    return cellphones\n",
    "\n",
    "# 用來抓市內電話號碼\n",
    "# 規則參考: https://zh.wikipedia.org/zh-tw/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E9%9B%BB%E8%A9%B1%E8%99%9F%E7%A2%BC\n",
    "def extract_telephones(text):\n",
    "    telephone_pattern = r'\\(?0[2-8]\\d{0,3}\\)?-?\\d{1,4}-?\\d{4}'\n",
    "    telephones = re.findall(telephone_pattern, text)\n",
    "    telephones = list(set(telephones))\n",
    "    telephones.sort()\n",
    "    return telephones\n",
    "\n",
    "# 用來抓 IP\n",
    "def extract_ip(text):\n",
    "    v4a = valid_IPv4s(text)\n",
    "    v6a = valid_IPv6s(text)\n",
    "    \n",
    "    # 結合兩者結果\n",
    "    ips = list(set(v4a + v6a))\n",
    "    ips.sort()\n",
    "    return ips\n",
    "\n",
    "# 用來初步抓罪名\n",
    "def extract_crime(text):\n",
    "    crimes = []\n",
    "    patterns = [r'違反(\\S+(?=[等違反]))等?[案罪]', r'因(\\S+(?=[等犯而]))等?[案罪]', r'因(\\S+)等?案', r'號(\\S+)等?案', r'違反(\\S+)等?案件']\n",
    "    for pattern in patterns:\n",
    "        crimes += re.findall(pattern, text)\n",
    "    crimes = [c.replace('違反', '').replace('等', '') for c in crimes if len(c) < 15 and len(c) > 1 ]\n",
    "    \n",
    "    crimes = [c for c in crimes if c]\n",
    "    crimes = [c for c in crimes if not str(c[0]).isdigit()]\n",
    "    crimes = [c for c in crimes if not '刑事判決' in c and not '聲請' in c and not ',' in c and not '起訴' in c]\n",
    "    crimes = [c for c in crimes if c]\n",
    "    \n",
    "    crimes = list(set(crimes))\n",
    "    crimes.sort()\n",
    "    \n",
    "    return crimes\n",
    "\n",
    "re_extractors = {\n",
    "    'crimes' : extract_crime,\n",
    "    'urls' : extract_urls,\n",
    "    'emails' : extract_emails,\n",
    "    'usernames' : extract_usernames,\n",
    "    'mobilephones' : extract_mobilephones,\n",
    "    'telephones' : extract_telephones,\n",
    "    'ips' : extract_ip,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e0d9113d-5520-48ef-a854-e67d49515db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ElementExtractor import Judicial_Parser\n",
    "import os, time, traceback, json, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9412555e-fb92-4e6b-bb67-ca047939695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36b98aa0-12d8-4d23-8f20-4a8152bff0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads to ./data.zip (2GB) and extracts to ./data/\n",
    "# data_utils.download_data_url(\"./\") # iis-ckip\n",
    "#data_utils.download_data_gdown(\"./\") # gdrive-ckip 已下載就不用再下載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "019599b6-28f9-4e35-b8ec-e374a18fef50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
      "C:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
      "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
     ]
    }
   ],
   "source": [
    "# To use GPU:\n",
    "#    1. Install tensorflow-gpu (see Installation)\n",
    "#    2. Set CUDA_VISIBLE_DEVICES environment variable, e.g. os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#    3. Set disable_cuda=False, e.g. ws = WS(\"./data\", disable_cuda=False)\n",
    "\n",
    "# 採坑心得\n",
    "# 新版已經沒有 tensorflow-gpu\n",
    "# 我使用 python 3.7 的環境 (conda create -n ckipcore python=3.7)\n",
    "# 先安裝 pip install -U ckiptagger[tf,gdown]\n",
    "# 再改用 Conda install tensorflow 去安裝匹配的新版\n",
    "# 搭配 disable_cuda=False 參數，從 windows 工作管理員之效能頁籤看起來，確實有使用 GPU\n",
    "\n",
    "ws = WS(\"./data\", disable_cuda=False)\n",
    "pos = POS(\"./data\", disable_cuda=False)\n",
    "ner = NER(\"./data\", disable_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c436454-555b-47e8-aa2b-2973cd18849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡繁轉換器 (暫時用不到)\n",
    "# import opencc\n",
    "# converter = opencc.OpenCC('t2s.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ace9c05f-db18-4bf0-985a-6ccefd5ec8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      ">>開始分析...\n",
      "[當前已分析數量] 3707\n",
      "[累計耗時] 0:1:6\n",
      "[當前檔案] C:\\課程\\交大\\論文\\案件整理\\202301\\最高法院刑事\\TPSM,110,台上,5654,20230111,1.json\n",
      "[RE] 分析中\n",
      ">> [crimes] []\n",
      ">> [urls] []\n",
      ">> [emails] []\n",
      ">> [usernames] []\n",
      ">> [mobilephones] []\n",
      ">> [telephones] []\n",
      ">> [ips] []\n",
      "--------------------------------------------------\n",
      "[WS] 分析中\n",
      "[POS] 分析中\n",
      "[NER] 分析中\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11852\\1870206075.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    118\u001b[0m                     \u001b[0mpos_sentence_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_sentence_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    119\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'[NER] 分析中'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 120\u001b[1;33m                     \u001b[0mentity_sentence_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_sentence_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos_sentence_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    121\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                     \u001b[1;31m# 整理 POS 結果\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\api.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, word_sentence_list, pos_sentence_list, character_normalization, batch_sentences, batch_characters)\u001b[0m\n\u001b[0;32m    318\u001b[0m                 \u001b[0mparital_label_sentence_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msample_list\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    319\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 320\u001b[1;33m                 \u001b[0mparital_label_sentence_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_label_for_a_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msample_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    321\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mpartial_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mlabel_sentence_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparital_label_sentence_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpartial_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\ckiptagger\\model_ner.py\u001b[0m in \u001b[0;36mpredict_label_for_a_batch\u001b[1;34m(self, sample_list)\u001b[0m\n\u001b[0;32m    424\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mc_v\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mc_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_k\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mw_v\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mw_v\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m             }\n\u001b[0;32m    428\u001b[0m         )\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    967\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    968\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 969\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    970\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    971\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1190\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1191\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1192\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1193\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1194\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1370\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1371\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1372\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1373\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1374\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1376\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1377\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1378\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1379\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1380\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1360\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[1;32m-> 1362\u001b[1;33m                                       target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1364\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\ckipcore\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1454\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[0;32m   1455\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1456\u001b[1;33m                                             run_metadata)\n\u001b[0m\u001b[0;32m   1457\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1458\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'[現在時間] {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "source_file = os.path.join(\n",
    "        'C:\\\\', '課程', '交大','論文','案件整理',\n",
    "        'json_files.txt'\n",
    "        )\n",
    "    \n",
    "count_file_done_num = 0\n",
    "clear_output()\n",
    "\n",
    "# 多工時使用\n",
    "skip = 0 # 要跳過從第幾開始\n",
    "\n",
    "print('-'*50)\n",
    "print(f'>>開始分析...')\n",
    "print(f'[當前已分析數量] {count_file_done_num}')\n",
    "\n",
    "with open(source_file, 'r', encoding='utf-8') as f:\n",
    "    # 2022~2023年判決書有211萬7,454個json檔\n",
    "    # 故一次讀一個處理，減少記憶體占用\n",
    "    raw_data = ''\n",
    "    \n",
    "    while 1: \n",
    "        # 開始逐案讀取資料分析\n",
    "        file = f.readline()\n",
    "        if '\\\\2023' in file: # 因為數量太多要跑太久，先從2023開始好了\n",
    "            count_file_done_num += 1\n",
    "\n",
    "            if '刑事' in file:\n",
    "                # 篩掉一些比較非刑案的\n",
    "                if not ('簡易' in file or '民事' in file or '補償' in file or '憲法' in file or '商業' in file):\n",
    "                    # 開始讀取裁判書內容\n",
    "                    file = file.strip()\n",
    "\n",
    "                    # 顯示進度\n",
    "                    temp_time = time.time()\n",
    "                    elapsed_time = temp_time - start_time\n",
    "                    hours = int(elapsed_time // 3600)  # 計算小時數\n",
    "                    minutes = int((elapsed_time % 3600) // 60)  # 計算分鐘數\n",
    "                    seconds = int(elapsed_time % 60)  # 計算剩餘秒數\n",
    "\n",
    "                    clear_output()\n",
    "                    print('-'*50)\n",
    "                    print(f'>>開始分析...')\n",
    "                    print(f'[當前已分析數量] {count_file_done_num}')\n",
    "                    print(f'[累計耗時] {hours}:{minutes}:{seconds}')\n",
    "                    print(f'[當前檔案] {file}')\n",
    "\n",
    "                    # 確定 file 存在\n",
    "                    if not os.path.isfile(file):\n",
    "                        print(f'[並非正常檔案] 跳過...')\n",
    "                        time.sleep(1)\n",
    "                        continue\n",
    "\n",
    "                    try:\n",
    "                        with open(file, 'r', encoding='utf-8') as jf:\n",
    "                            json_data = json.load(jf)\n",
    "                    except:\n",
    "                        x = traceback.format_exc()\n",
    "                        print(x)\n",
    "                        time.sleep(3)\n",
    "                        continue\n",
    "\n",
    "                    # 資料清洗\n",
    "                    parser = Judicial_Parser(json_data)\n",
    "\n",
    "                    jid = parser.jid.strip().replace(' ', '')\n",
    "                    date = parser.dateSTR.strip().replace(' ', '')\n",
    "                    raw = parser.raw\n",
    "                    text = parser.text\n",
    "                    text_u = parser.text_u\n",
    "\n",
    "                    # 確定是否已經在資料庫內\n",
    "                    check_res = cur_POS.execute(f\"SELECT jid FROM results WHERE jid='{jid}'\")\n",
    "                    temp = check_res.fetchone()\n",
    "                    if temp:\n",
    "                        print(f'[JID] {jid}')\n",
    "                        print('>>此JID發現資料庫已有，跳過')\n",
    "                        continue\n",
    "                        \n",
    "                    print('-'*50)\n",
    "                    print(text_u)\n",
    "                    print('-'*50)\n",
    "\n",
    "                    # 沒有在資料庫內才處理\n",
    "\n",
    "                    '''\n",
    "                    ------------------------------------------------------------------\n",
    "                    RE 擷取\n",
    "                    ------------------------------------------------------------------\n",
    "                    '''\n",
    "                     # Input text\n",
    "                    print('[RE] 分析中')\n",
    "                    # 擷取 RE 結果\n",
    "                    re_dict = dict()\n",
    "                    for re_type, re_func in re_extractors.items():\n",
    "                        re_temp_result = re_func(text_u)\n",
    "                        if re_temp_result:\n",
    "                            re_dict[re_type] = re_temp_result\n",
    "                        print(f'>> [{re_type}] {re_temp_result}')\n",
    "\n",
    "                    '''\n",
    "                    ------------------------------------------------------------------\n",
    "                    POS & NER 擷取\n",
    "                    ------------------------------------------------------------------\n",
    "                    '''\n",
    "                    # Input text\n",
    "                    print('-'*50)\n",
    "                    print('[WS] 分析中')\n",
    "                    sentence_list = text_u.split('。')\n",
    "                    word_sentence_list = ws(\n",
    "                        sentence_list,\n",
    "                        # sentence_segmentation = True, # To consider delimiters\n",
    "                        # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}), # This is the defualt set of delimiters\n",
    "                        # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "                        # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "                    )\n",
    "                    print('[POS] 分析中')\n",
    "                    pos_sentence_list = pos(word_sentence_list)\n",
    "                    print('[NER] 分析中')\n",
    "                    entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "\n",
    "                    # 整理 POS 結果\n",
    "                    pos_dict = dict()\n",
    "                    for idx, words in enumerate(word_sentence_list):\n",
    "                        for idx2, word in enumerate(words):\n",
    "                            temp_type = pos_sentence_list[idx][idx2]\n",
    "                            word = word.strip().replace(' ', '').replace(':', '').replace(',', '')\n",
    "                            pos_dict.setdefault(temp_type, set())\n",
    "                            pos_dict[temp_type].add(word)\n",
    "\n",
    "                    # 擷取 NER 結果\n",
    "                    ner_dict = dict()\n",
    "                    for e in entity_sentence_list:\n",
    "                        for ee in e:\n",
    "                            ner_type = ee[2]\n",
    "                            ner_dict.setdefault(ner_type, set())\n",
    "                            temp_ner_result = ee[3].strip().replace(' ', '').replace(':', '').replace(',', '')\n",
    "                            ner_dict[ner_type].add(temp_ner_result)\n",
    "                    print('-'*50)\n",
    "\n",
    "                    '''\n",
    "                    ------------------------------------------------------------------\n",
    "                    寫入 DB Table\n",
    "                    ------------------------------------------------------------------\n",
    "                    '''\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 RE 結果')\n",
    "                    for re_type, re_keywords in re_dict.items():\n",
    "                        values_str = ','.join(re_keywords)\n",
    "                        to_db_content = \"INSERT INTO results VALUES(?, ?, ?, ?)\" # ? 是一個參數占位符，代表將要插入的值。\n",
    "                        cur_RE.execute(to_db_content, (jid, date, re_type, values_str))\n",
    "                    con_RE.commit()\n",
    "\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 POS 結果')\n",
    "                    for temp_type, temp_keywords in pos_dict.items():\n",
    "                        temp_keywords = {tk.strip().replace(' ', '').replace(',', '').replace(':', '') for tk in temp_keywords if len(tk.strip().replace(' ', '').replace(',', '').replace(':', '')) > 1}\n",
    "                        temp_keywords = list(temp_keywords)\n",
    "                        temp_keywords.sort()\n",
    "                        values_str = ','.join(temp_keywords)\n",
    "                        to_db_content = \"INSERT INTO results VALUES(?, ?, ?, ?)\" # ? 是一個參數占位符，代表將要插入的值。\n",
    "                        cur_POS.execute(to_db_content, (jid, date, re_type, values_str))\n",
    "                    con_POS.commit()\n",
    "\n",
    "                    print('-'*50)\n",
    "                    print('>>準備寫入 NER 結果')\n",
    "                    for temp_type, temp_keywords in ner_dict.items():\n",
    "                        temp_keywords = {tk.strip().replace(' ', '').replace(',', '').replace(':', '') for tk in temp_keywords if len(tk.strip().replace(' ', '').replace(',', '').replace(':', '')) > 1}\n",
    "                        temp_keywords = list(temp_keywords)\n",
    "                        temp_keywords.sort()\n",
    "                        values_str = ','.join(temp_keywords)\n",
    "                        to_db_content = \"INSERT INTO results VALUES(?, ?, ?, ?)\" # ? 是一個參數占位符，代表將要插入的值。\n",
    "                        cur_NER.execute(to_db_content, (jid, date, re_type, values_str))\n",
    "                    con_NER.commit()\n",
    "\n",
    "                    print('-'*50)\n",
    "                    print('>>完成!!!')\n",
    "\n",
    "                \n",
    "# 關閉 DB占用\n",
    "con_RE.close()\n",
    "con_POS.close()\n",
    "con_NER.close()\n",
    "\n",
    "# 顯示統計結果\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours = int(elapsed_time // 3600)  # 計算小時數\n",
    "minutes = int((elapsed_time % 3600) // 60)  # 計算分鐘數\n",
    "seconds = int(elapsed_time % 60)  # 計算剩餘秒數\n",
    "print(f'[累計耗時] {hours}:{minutes}:{seconds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "049e0fab-b8a1-4108-be0a-2001a7681577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'最高法院刑事判決110年度台上字第5654號110年度台上字第5655號 \\n上 訴 人 \\n (被 告) 許玉秀 \\n選任辯護人 吳澄潔律師上 訴 人 \\n (被 告) 劉富榮 \\n選任辯護人 楊靖儀律師上 訴 人 \\n (被 告) 傅 中 \\n選任辯護人 黃燦堂律師上 訴 人 \\n (被 告) 劉信宏 \\n選任辯護人 陳怡融律師上 訴 人 \\n (被 告) 李鎮衛 \\n選任辯護人 王勝彥律師 陳魁元律師上 訴 人\\n (參與人) 三山國王宮 \\n代 表 人 邱善龍 \\n上列上訴人等因被告等違反貪污治罪條例案件,不服臺灣高等法院高雄分院中華民國110年5月12日第二審判決(109年度上訴字第416、417號,起訴及追加起訴案號:臺灣屏東地方檢察署105年度偵字第8509、6714、9531號,106年度偵字第6634、8123、8427號),提起上訴,本院判決如下。主文 原判決關於許玉秀、劉富榮、傅中、劉信宏、李鎮衛如其事實欄 二部分,暨參與人三山國王宮部分均撤銷,發回臺灣高等法院高雄分院。其他上訴駁回。理由 壹、撤銷發回(許玉秀、劉富榮、傅中、劉信宏、李鎮衛關於原判決事實欄《下稱事實欄》二及三山國王宮)部分。一、本件原審審理結果,認定上訴人即被告許玉秀、傅中、李鎮衛為公務員,與劉富榮、劉信宏(下或稱許玉秀等5人)有事實欄二相關所載違反貪污治罪條例、商業會計法、偽造文書犯行,因而撤銷第一審該部分科刑及就上訴人即參與人三山國王宮諭知沒收、追徵之判決,改判仍依想像競合犯,從一重論處許玉秀等5人共同犯或與公務員共同犯利用職務機會詐取財物罪刑,並諭知相關沒收、追徵。固非無見。二、惟查。㈠憲法第16條規定保障人民之訴訟權,就刑事被告而言,包括其在訴訟上應享有充分之防禦權(司法院釋字第582號解釋意旨參照)。國家經由刑事審判程序,對被告之特定犯罪事實,決定國家刑罰權存在與否及具體內容,應兼顧實體上發現真實及程序上公平正當。又刑事訴訟法第95條第1項第1款規定,訊問被告應先告知犯罪嫌疑及所犯所有罪名。罪名經告知後,認為應變更者,應再告知。所謂「犯罪嫌疑及所犯所有罪名」,除起訴書所記載之犯罪事實及所犯法條外,自包含依刑事訴訟法第267條規定起訴效力所擴張之犯罪事實及罪名,暨依同法第300條規定變更起訴法條後之新罪名,而同法第288條第3項後段所謂「審判長就被告被訴事實為訊問者」,依相同理由,自亦包括起訴效力擴張之犯罪事實及變更起訴法條之同一性事實。法院若認為有此等擴張(增加)或更正(變更)起訴之犯罪事實情形時,應隨時、但至遲於審判期日踐行上開告知程序,俾被告與其辯護人得以適時知悉而充分行使防禦權及辯護權,始能避免突襲性裁判,以達兼顧發現真實和程序正義之目的。如法院就擴張(增加)或更正(變更)之犯罪事實或所犯罪名,或未踐行告知程序,或僅踐行告知程序,而未依刑事訴訟法第96條、第288條第3項、第288條之1、第288條之2、第289條等規定,踐行賦予辯明犯罪嫌疑及辯論證據證明力之機會等程序,即辯論終結,逕行就起訴效力所及之犯罪事實或變更起訴法條之同一性犯罪事實而為判決,則就認定被告有此等犯罪事實及所犯罪名而言,無異剝奪被告與其辯護人依正當法律程序應受保障之辯明及辯論等程序上權利,而顯然影響於判決結果,其所踐行之訴訟程序,難謂適法。依事實欄二認定之事實,許玉秀等5人為圖三山國王宮(即原判決所載長治國王宮)不法之所有,於民國105年屏東縣長治鄉公所(下稱長治鄉公所)舉辦所載「長治鄉陣頭遶境活動」(與「長治鄉民俗技藝熱鬧迎新年活動」合稱「王爺奶奶回娘家」活動),明知或可得預見長治鄉公所購買礦泉水、宣導品(琉璃車掛吊飾品1,000個)僅各實際支出新臺幣(下同)2,000元、2萬2,500元,猶持傅中向楊女佩(未據起訴)取得(原判決附表《下稱附表》三編號3)勝豐企業社所虛開總價9萬5,000元之免用統一發票收據,向屏東縣政府辦理核銷,致承辦人員誤認該憑證所載屬實而予以核發補助款,共同以此方式詐領7萬500元,因認許玉秀等5人此部分亦涉犯貪污治罪條例第5條第1項第2款(與公務員)利用職務詐取財物罪、刑法第216條、第213條、第215條之行使公務員登載不實文書、業務登載不實文書罪刑,並敘明第一審誤認該(附表三編號3)部分並無不實,尚有未洽等情(見原判決第5至8頁、第63頁首行至第5行、第80頁第7至12行)。惟該部分未在檢察官起訴或追加起訴書犯罪事實所載範疇,亦非第一審認定有罪之事實,而依據原審筆錄之記載,審判長於審判期日雖已告知被告相關罪名,但於調查證據程序後,似僅以(追加)起訴書或第一審判決所認定之犯罪事實訊問被告,而未及於上開擴張之犯罪事實(見原審上訴字第416號卷㈣第267頁以下、上訴字第417號卷㈣第293頁以下筆錄),致許玉秀等5人及其等辯護人無從在原審就原判決所增列認定之此部分犯罪事實,為適時、充分地行使法律所賦予之辯明及辯論(護)權,有礙其等訴訟防禦權之行使,遽行辯論及判決,依前揭說明,自有違誤,且原判決復未說明該非屬(追加)起訴書犯罪事實記載之犯行,如何得併予審理之理由,併有理由欠備之違法。㈡科刑判決所認定之事實,與所採之證據不相適合,或認定事實與卷證資料不符,即屬判決理由矛盾之當然違背法令。審理事實之法院,對於被告有利及不利之證據,應一律注意,詳為調查,綜合全案證據資料,本於經驗及論理法則以定其取捨,並將取捨證據及得心證之理由於判決內詳為說明。犯罪事實應依證據認定,有罪之判決書,應於理由內記載認定犯罪事實所憑之證據及其認定之理由,否則即有理由不備之違法。原判決認許玉秀等5人以傅中向楊女佩取得附表三編號3之(虛開金額9萬5,000元)免用統一發票收據核銷而詐取7萬500元,依理由之說明,係以本件雖確有訂購1,000個琉璃車掛吊飾品(宣導品),但扣除附表五之一編號⑵至⑼之費用,本次活動補助款僅剩2萬2,500元可供支付,傅中不可能自行墊付全部貨款,因認其僅將剩餘補助款2萬2,500元交付楊女佩,是傅中以前揭收據用以核銷除實際支出之礦泉水2,000元及宣導品2萬2,500元外,餘款7萬500元非屬實際支出,為許玉秀等5人利用職務上機會所詐取等旨(見原判決第62頁第25行至次頁第5行)。但:⒈原判決理由除說明附表三編號1、2及附表四所示不實單據取得經過之依據外,就上開附表三編號3之免用統一發票收據究如何取得,並未敘明其所憑之證據及認定之理由(同判決第34頁第10行以下),已屬判決理由不備。⒉稽之卷證,傅中於106年8月3日在法務部調查局屏東縣調查站(下稱調查站)詢問時供稱:「(據楊女佩筆錄述稱:『我記得遶境活動結束後一至兩個月,傅中約我在長治鄉公所門口交付現金9萬5,000元給我。』,是否有此事?)大致上是有這樣,但是,地點不是在長治鄉公所門口,而是在長治鄉公所辦公室,當時是因李鎮衛請假,交待我把該筆款項交給楊女佩,但是金額應該是這樣。」(見106年度偵字第6634號卷㈠第63頁背面)同年8月10日於調查站供述:「(琉璃吊飾宣導品款項長治鄉公所如何支付?)是我通知勝豐企業社來鄉公所領款,並以現金9萬5千元支付給前述勝豐企業社接洽的女員工」(同上偵查卷第195頁)。如若非虛,依傅中及所載楊女佩供述,傅中似有交付附表三編號3免用統一發票收據所載相同金額(9萬5,000元)之現金與楊女佩,原判決上開推論即與卷證未盡相符,且依上開106年8月3日調查站之筆錄,調查員曾引用楊女佩之供述詢問傅中,但卷內似無楊女佩之筆錄可參,亦未見原審就此部分調查、釐清,則傅中因購買宣導品支付楊女佩之金額究竟若干?楊女佩取得該款項後是否全部或部分返還傅中或劉富榮?楊女佩之相關供述為何?凡此,俱與許玉秀等5人此部分是否該當(與公務員)利用職務上之機會詐取財物、文書登載不實罪攸關,原審並未翔實調查、審認,闡述其憑以認定之依據,泛以上開推論之方式逕為不利許玉秀等5人之認定,自不足以昭折服,有未依證據認定事實、證據調查未盡及理由矛盾、欠備之違法。㈢依原判決事實之記載及理由之說明,李鎮衛於證人(長治鄉公所民政課課員)劉照璋向其表示「王爺奶奶回娘家」活動經費申請採購程序有違法之虞而拒絕承辦後續核銷業務時,已可預見本件相關單據恐有不實情形,仍不違背其本意接替劉照璋申請核發補助款,就所涉公務員利用職務機會詐取財物、行使公務員登載不實文書、業務登載不實文書犯行有不確定故意,與具直接故意之許玉秀、劉富榮、傅中、劉信宏有犯意聯絡及行為分擔等旨(見原判決第46頁第6行以下至第51頁第20行)。但。⒈複數行為人分別基於直接故意或間接故意實行犯罪行為,固非不得成立共同正犯,但必所犯之罪非以「明知」為要件。刑法第213條、第215條之登載不實罪,以公務員或從事業務之人所登載不實之事項出於明知為前提要件,所謂明知,係指直接故意而言,若為間接(不確定)故意或過失,既無從以該罪相繩,自無成立共同正犯之可言。原判決以李鎮衛具不確定故意論以共犯上開登載不實文書罪,自有適用法則不當之違法。⒉依原判決所引劉照璋於調查站、第一審之供述:我向李鎮衛表示,因完全沒參與該活動,所以不願意蓋章,李鎮衛也沒說什麼,李鎮衛要我當承辦人是因為我負責宗教禮俗業務,當時我認為要發公文可以,但我已經想要退休了,不想再辦這件事情,公文下來後,有問李鎮衛這個活動要如何辦、後續要如何處理,但他都沒有明確回答我,所以我就不想蓋章等語(見原判決第46頁第7行至次頁第4行);再依卷內筆錄所載,劉照璋於第一審供稱:「(黏貼單據時,有無發現單據有問題?)沒有」、「(你有無跟課長《即李鎮衛,下同》表示疑慮?怕違法?)我沒有講這樣」、「(課長為何要跟你講〈不覺得活動有違法等〉這一段?)那是因為我不想蓋章,就不想辦」、「(有無跟課長講你不想蓋章的原因?)沒有,我想不起來」等語(見第一審訴字第625號卷㈡第525、526、534、535頁)。倘均無訛,劉照璋之供述似僅止於證明其因未參與「王爺奶奶回娘家」活動,李鎮衛復未明確指示如何辦理,且其擬退休始拒絕承辦後續核銷請款業務,不及於其曾向李鎮衛陳述本件有單據不實等違法情事,原判決逕認劉照璋曾以該活動經費申請採購程序有「違法」之虞為由向李鎮衛表示不願意承辦後續業務,已與卷證不符。則倘劉照璋並非以本案有違法情事為由向李鎮衛表達拒絕辦理相關業務,李鎮衛以循合法程序處理等旨勸說其續辦,能否逕認李鎮衛已預見本件有以不實單據核銷之違法情事,而有利用職務上機會詐取財物之主觀故意,即值研酌。原審亦未詳查究明,逕以劉照璋上開證述及李鎮衛部分供述推論李鎮衛有所載犯行之不確定故意,容有查證未盡及理由欠備之缺失。三、上述違背法令,或為許玉秀等5人上訴意旨所指摘,或為本\\n 院得依職權調查之事項,且影響於事實之確定,本院無可據\\n 以為裁判,應認此部分有撤銷發回更審之原因。原判決關於\\n 參與人三山國王宮因許玉秀等5人利用職務機會詐取財物犯\\n 罪所得部分,本案此部分既有上開違法之處,影響犯罪所得\\n 之認定,所諭知三山國王宮之財產沒收、追徵之計算基礎,\\n 即失其依附,應併予發回。又㈠原判決未認定許玉秀屬商業會計法第4條所稱之商業負責人,則其如何得論以同法第71條第1款填製不實會計憑證罪之共犯,漏未敘明其理由;㈡李鎮衛被訴想像競合犯商業會計法第71條第1款填製不實會計憑證罪部分,第一審及原審均不另為無罪之諭知(見第一審判決第101、102頁,原判決第87、88頁),因未據上訴,業已確定,非本院審理範圍,至於原判決事實欄二之㈢所記載李鎮衛基於不違背其本意之填製不實會計憑證之犯意聯絡(見原判決第7頁第13、14行),前後齟齬,是否誤植,前揭有罪部分,更審後如仍認犯罪,允宜注意及之,均附此敘明。貳、上訴駁回(傅中關於事實欄一)部分。一、按刑事訴訟法第377條規定,上訴於第三審法院,非以判決違背法令為理由,不得為之。是提起第三審上訴,應以原判決違背法令為理由,係屬法定要件。如果上訴理由書狀並未依據卷內訴訟資料,具體指摘原判決不適用何種法則或如何適用不當,或所指摘原判決違法情事,顯與法律規定得為第三審上訴理由之違法情形,不相適合時,均應認其上訴為違背法律上之程式,予以駁回。二、本件原審審理結果,認定傅中有事實欄一相關所載之違反貪污治罪條例、政府採購法各犯行明確,因而撤銷第一審關於事實欄一之㈡(即附表一編號1、2、3-1)部分科刑之判決,改判依想像競合犯,從一重論處傅中如其附表一之一編號1至3所示犯貪污治罪條例第4條第1項第5款之違背職務收受賄賂3罪刑,並諭知沒收及追徵,另維持第一審關於事實欄一之㈢(即附表一編號5)部分,論處傅中附表一之一編號4所示犯貪污治罪條例第5條第1項第3款之對於職務上之行為,收受賄賂罪刑,並諭知沒收及追徵之判決,駁回檢察官及其此部分在第二審之上訴,已載敘其調查取捨證據之結果及憑以認定各該犯罪事實之心證理由,就傅中否認犯罪之供詞及所辯,認非可採,亦依調查所得證據予以論述指駁,有卷存資料可資覆按。三、上訴意旨略以:㈠傅中係清潔人員,僅係受指示上網代登長治鄉公所招標事項等機械性、肉體性勞務之人員,此經證人張鳳祺、黃瑞英、許玉秀等證述在卷,其對於長治鄉公所之招標、開標、決標等,無任何影響力,亦非其業務,非屬公務員,且原判決對上開有利證據未說明不採納之理由,亦未敘明其有何法定職務權限,逕以貪污罪相繩,有理由不備之違法。㈡其與共同被告黃宥豐、李水木、黃競德、李坤達(均經判處罪刑確定)無「顧標」之犯意聯絡及行為分擔,此經黃宥豐證述明確,原判決認定有誤。四、犯罪事實之認定、證據之取捨及證明力之判斷,俱屬事實審法院之職權,此項職權之行使,倘不違背客觀存在之經驗法則或論理法則,即不違法,觀諸刑事訴訟法第155條第1項規定甚明,自無許當事人任憑主觀妄指為違法,而資為合法之第三審上訴理由。原判決認定傅中上開貪污、妨害投標各犯行,係綜合傅中部分供述、證人即同案被告黃貴得(已歿,經判決不受理確定)、黃宥豐、證人顏鳳嬌不利於傅中之證詞、卷附傅中與黃貴得(持顏鳳嬌之行動電話)、黃宥豐間之通訊監察譯文,酌以所列其餘證據資料及案內其他證據調查之結果而為論斷,詳敘憑為判斷傅中為任職長治鄉公所之公務員,就負責之附表一編號1、2、3-1、5所載工程標案,於所示時間、地點收受得標廠商翔盈土木包工業(下稱翔盈土木包)負責人黃貴得交付工程總金額約10%之賄款,其中附表一編號1、2、3-1並夥同黃宥豐、李水木、黃競德、李坤達等人以所載「顧標」之攔阻、勸退等非法方法阻止其他廠商投標,使翔盈土木包得以順利得標,所為分別該當(附表一編號1、2、3-1)違背職務收受賄賂、妨害投標罪及(附表一編號5)對於職務上行為收受賄賂罪構成要件之理由綦詳,復說明(附表一編號1、2、3-1)黃宥豐等人之「顧標」行為係受傅中之指示並由其指定僅翔盈土木包即黃貴得可進入長治鄉公所投標,渠等就妨害投標犯行有犯意聯絡及行為分擔,其審酌之依據及判斷之理由,另本於證據取捨之職權行使,對於證人黃貴得嗣於審理中改稱交付傅中之金錢係「紅利」,而非賄賂,暨證人黃宥豐供稱(105年6月1日)與傅中聯繫係相約打籃球場次事宜等旨證詞,何以不足為傅中有利之認定,亦依調查所得之證據,於理由內論駁明白。凡此,概屬原審採證認事職權之合法行使,核其各論斷說明,衡諸經驗及論理等證據法則皆無違背,不容任意指為違法。又刑法第10條第2項第1款前段規定依法令服務於國家、地方自治團體所屬機關而具有法定職務權限之公務員,著重在其服務於上開機關之身分,即所謂身分公務員。所稱「依法令」係指依法律與命令而言,此之命令又包括行政程序法第150條之法規命令與第159條之行政規則在內,此類公務員之任用方式,或依考試、或經選舉、聘用、派用、僱用、約用,均所不論,亦不論其係專職或兼職、長期性或臨時性、職位高低,只須有法令之任用依據即可;至所指「法定」職務權限,自亦包含依法律與以行政命令所定之職務在內,而以行政命令者,如組織規程、處務規程、業務管理規則、機關其他之內部行政規章等固無庸論,即機關長官基於內部事務授權分配而為之職務命令,亦屬之。凡為公務員在其職務範圍內所應為或得為之事務均為其「法定職務權限」,不論究係永久性或暫時兼辦性質,均包括在內,更不以最後有決定之職權為限。原判決依憑許玉秀及證人張鳳祺、黃瑞英、李天惠之供述、卷附長治鄉公所函文檢送之人事任用及工程發包作業程序等資料,就傅中係長治鄉公所依工友管理要點任用之工友,並經鄉長許玉秀指派至行政室協助處理該室發包中心標案文書製作、公告上網等事務,長治鄉公所行政室之公共工程招標、採購相關業務,自屬其法定職務權限,為依法令服務於國家所屬機關,並經機關首長以職務命令指派負責辦理公共工程招標業務而具法定職務權限之身分公務員等旨,已於理由內論述明白,所為論斷說明,與卷內資料委無不合。且依原判決確認之事實,傅中雖以工友任用,且屬(編制內)清潔隊員,但於長治鄉公所行政室負責公共工程招標職務,與單純機械性、肉體性勞務之工作不同,原判決縱未特予說明,亦無傅中上訴意旨所指理由欠備之違失。五、依上所述,傅中上訴意旨無非係對原審採證認事職權之適法行使,徒以自己說詞,任意指為違法,且為單純事實之爭執,難謂已符合首揭法定上訴要件,應認其此部分上訴為不合法律上之程式,予以駁回。據上論結,應依刑事訴訟法第397條、第401條、第395條前段,判決如主文。中華民國112年1月11日 刑事第七庭審判長法官 段景榕 法官 沈揚仁 法官 楊力進 法官 汪梅芬 法官 宋松璟本件正本證明與原本無異 書記官 石于倩中華民國112年1月17日'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "475bdaf4-d65b-410f-bdb2-bb72d82f2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "等因被告等違反貪污治罪條例案件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "62ccf68f-6987-429e-aa78-d035c9624693",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['貪污治罪條例']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#patterns = [r'違反(\\S+(?=[等違反]))等?[案罪]', r'因(\\S+(?=[等犯而]))等?[案罪]', r'因(\\S+)等?案', r'號(\\S+)等?案']\n",
    "re.findall(r'違反(\\S+)等?案件', text_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0733255-1058-45a8-9a3d-ef6d32922877",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
