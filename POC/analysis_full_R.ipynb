{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44d7c23a-be4c-4ac9-8eb8-67a1925b385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "'''\n",
    "一共開 3 個 DB\n",
    "1. 存 NER 結果\n",
    "2. 存 POS 結果\n",
    "3. 存 RE 結果: 含網址、Email、Username、(行動、市內)電話、IP\n",
    "'''\n",
    "\n",
    "con_NER = sqlite3.connect(\"JudicialAnalysis_R_NER.db\")\n",
    "cur_NER = con_NER.cursor()\n",
    "\n",
    "con_POS = sqlite3.connect(\"JudicialAnalysis_R_POS.db\")\n",
    "cur_POS = con_POS.cursor()\n",
    "\n",
    "con_RE = sqlite3.connect(\"JudicialAnalysis_R_RE.db\")\n",
    "cur_RE = con_RE.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8864568-2b00-4df6-b1f6-80efdb12c0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建 Table\n",
    "new = 0\n",
    "if new:\n",
    "    cur_NER.execute(\"CREATE TABLE results(jid, date, keyword_type, keywords)\")\n",
    "    con_NER.commit()\n",
    "    con_NER.close()\n",
    "    \n",
    "    cur_POS.execute(\"CREATE TABLE results(jid, date,  keyword_type, keywords)\")\n",
    "    con_POS.commit()\n",
    "    con_POS.close()\n",
    "    \n",
    "    cur_RE.execute(\"CREATE TABLE results(jid, date, keyword_type, keywords)\")\n",
    "    con_RE.commit()\n",
    "    con_RE.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27dc84cf-058c-4bd2-a6b5-d35954334f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把原本裁判書檔按順序反過來\n",
    "# 從 2023年12月開始\n",
    "reverse = 0 # 已經做過就不用再做了\n",
    "if reverse:\n",
    "    import os \n",
    "\n",
    "    source_file = os.path.join(\n",
    "            'C:\\\\', '課程', '交大','論文','案件整理',\n",
    "            'json_files.txt'\n",
    "            )\n",
    "\n",
    "    with open(source_file, 'r', encoding='utf-8') as f:\n",
    "        # 2022~2023年判決書有211萬7,454個json檔\n",
    "        # 故一次讀一個處理，減少記憶體占用\n",
    "        json_files_R = f.read().strip().split('\\n')\n",
    "\n",
    "    json_files_R.sort(reverse=True)\n",
    "    json_files_R = [f for f in json_files_R if os.path.isfile(f)]\n",
    "\n",
    "    source_file_R = os.path.join(\n",
    "            'C:\\\\', '課程', '交大','論文','案件整理',\n",
    "            'json_files_R.txt'\n",
    "            )\n",
    "    \n",
    "    json_files_R_STR = '\\n'.join(json_files_R).strip()\n",
    "    \n",
    "    with open(source_file_R, 'w', encoding='utf-8') as f:\n",
    "        # 2022~2023年判決書有211萬7,454個json檔\n",
    "        # 故一次讀一個處理，減少記憶體占用\n",
    "        f.read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c12b4e2-c1ad-467e-8d08-af2606cd0e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from valid_IP import valid_IPv4s, valid_IPv6s\n",
    "\n",
    "# 用來抓網址s、Domains\n",
    "def extract_urls(text):\n",
    "    urls = []\n",
    "    patterns = [r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', r'https?://([\\w\\.\\-]+)']\n",
    "    for url_pattern in patterns:\n",
    "        urls += re.findall(url_pattern, text)\n",
    "    urls = list(set(urls))\n",
    "    urls.sort()\n",
    "    return urls\n",
    "\n",
    "# 用來抓 Emails\n",
    "def extract_emails(text):\n",
    "    email_pattern = r'[\\w.-]+@[\\w.-]+'\n",
    "    emails = re.findall(email_pattern, text)\n",
    "    emails = list(set(emails))\n",
    "    emails.sort()\n",
    "    return emails\n",
    "\n",
    "# 用來抓 Usernames\n",
    "# \\w : 包括(alphanumeric) [0-9a-zA-Z_]\n",
    "# 後來發現 \\w 在 python3 是 unicode 也支持中文\n",
    "# 解決方法: 要在 re.findall 第三個參數加入 re.A 恢復使用 ASCII，例如: re.findall(r\"\\w\", text, re.A))\n",
    "# 我是乾脆直接指定 [0-9a-zA-Z_]\n",
    "def extract_usernames(text):\n",
    "    # 用戶名模式：開頭可能有@，接著是字母、數字、下劃線、點或破折號\n",
    "    username_pattern = r'@?[a-zA-Z][0-9a-zA-Z_.-]+'\n",
    "    usernames = re.findall(username_pattern, text)\n",
    "    usernames = list(set(usernames))\n",
    "    usernames.sort()\n",
    "    return usernames\n",
    "\n",
    "# 用來抓手機號碼\n",
    "def extract_mobilephones(text):\n",
    "    # 手機可能有 - 也可能沒有 -\n",
    "    # 國際號碼可能有 886\n",
    "    cellphones = []\n",
    "    cellphone_patterns = [r'(\\+?886\\d{3}-?\\d{3}-?\\d{3})', r'(0\\d{3}-?\\d{3}-?\\d{3})']\n",
    "    for cellphone_pattern in cellphone_patterns:\n",
    "        cellphones += re.findall(cellphone_pattern, text)\n",
    "    cellphones = list(set(cellphones))\n",
    "    cellphones.sort()\n",
    "    return cellphones\n",
    "\n",
    "# 用來抓市內電話號碼\n",
    "# 規則參考: https://zh.wikipedia.org/zh-tw/%E4%B8%AD%E8%8F%AF%E6%B0%91%E5%9C%8B%E9%9B%BB%E8%A9%B1%E8%99%9F%E7%A2%BC\n",
    "def extract_telephones(text):\n",
    "    telephone_pattern = r'\\(?0[2-8]\\d{0,3}\\)?-?\\d{1,4}-?\\d{4}'\n",
    "    telephones = re.findall(telephone_pattern, text)\n",
    "    telephones = list(set(telephones))\n",
    "    telephones.sort()\n",
    "    return telephones\n",
    "\n",
    "# 用來抓 IP\n",
    "def extract_ip(text):\n",
    "    v4a = valid_IPv4s(text)\n",
    "    v6a = valid_IPv6s(text)\n",
    "    \n",
    "    # 結合兩者結果\n",
    "    ips = list(set(v4a + v6a))\n",
    "    ips.sort()\n",
    "    return ips\n",
    "\n",
    "# 用來初步抓罪名\n",
    "def extract_crime(text):\n",
    "    crimes = []\n",
    "    patterns = [\n",
    "        r'違反(\\S{2,20})等案', \n",
    "        r'違反(\\S{2,20})案?', \n",
    "        r'違反(\\S{2,20})等罪', \n",
    "        r'違反(\\S{2,20})罪',\n",
    "        r'因(\\S{2,20})等案',\n",
    "        r'因(\\S{2,20})案', \n",
    "        r'因(\\S{2,20})等罪', \n",
    "        r'因(\\S{2,20})罪', \n",
    "        r'號(\\S{2,20})等案', \n",
    "        r'號(\\S{2,20})案?',\n",
    "        r'號(\\S{2,20})等?罪', \n",
    "        r'號(\\S{2,20})等罪',\n",
    "        r'號(\\S{2,20})罪',\n",
    "        r'被告(\\S{2,20})等案', \n",
    "        r'被告(\\S{2,20})案', \n",
    "        r'被告(\\S{2,20})等罪'\n",
    "        r'被告(\\S{2,20})罪'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        crimes += re.findall(pattern, text)\n",
    "    crimes = [c.replace('違反', '').replace('等', '') for c in crimes if len(c) < 15 and len(c) > 1 ]\n",
    "    \n",
    "    crimes = [c for c in crimes if c]\n",
    "    crimes = [c for c in crimes if not str(c[0]).isdigit()]\n",
    "    crimes = [c for c in crimes if not '刑事判決' in c and not '聲請' in c and not ',' in c and not '起訴' in c and '刑責' not in c and not '刑責' in c and not '檢察' in c and not '上開' in c and not '事實' in c and not '被告' in c]\n",
    "    # 檢查是否有包含\n",
    "    fix_crimes = []\n",
    "    for c in crimes:\n",
    "        drop = 0\n",
    "        for cc in crimes:\n",
    "            if cc == c:\n",
    "                continue\n",
    "            if len(cc) > len(c) and c in cc:\n",
    "                drop += 1\n",
    "        if drop == 0:\n",
    "            fix_crimes.append(cc)\n",
    "    \n",
    "    crimes = [c for c in fix_crimes if c]\n",
    "    \n",
    "    crimes = list(set(crimes))\n",
    "    crimes.sort()\n",
    "    \n",
    "    return crimes\n",
    "\n",
    "re_extractors = {\n",
    "    'crimes' : extract_crime,\n",
    "    'urls' : extract_urls,\n",
    "    'emails' : extract_emails,\n",
    "    'usernames' : extract_usernames,\n",
    "    'mobilephones' : extract_mobilephones,\n",
    "    'telephones' : extract_telephones,\n",
    "    'ips' : extract_ip,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d9113d-5520-48ef-a854-e67d49515db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ElementExtractor import Judicial_Parser\n",
    "import os, time, traceback, json, re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9412555e-fb92-4e6b-bb67-ca047939695f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b98aa0-12d8-4d23-8f20-4a8152bff0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloads to ./data.zip (2GB) and extracts to ./data/\n",
    "# data_utils.download_data_url(\"./\") # iis-ckip\n",
    "#data_utils.download_data_gdown(\"./\") # gdrive-ckip 已下載就不用再下載"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019599b6-28f9-4e35-b8ec-e374a18fef50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use GPU:\n",
    "#    1. Install tensorflow-gpu (see Installation)\n",
    "#    2. Set CUDA_VISIBLE_DEVICES environment variable, e.g. os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "#    3. Set disable_cuda=False, e.g. ws = WS(\"./data\", disable_cuda=False)\n",
    "\n",
    "# 採坑心得\n",
    "# 新版已經沒有 tensorflow-gpu\n",
    "# 我使用 python 3.7 的環境 (conda create -n ckipcore python=3.7)\n",
    "# 先安裝 pip install -U ckiptagger[tf,gdown]\n",
    "# 再改用 Conda install tensorflow 去安裝匹配的新版\n",
    "# 搭配 disable_cuda=False 參數，從 windows 工作管理員之效能頁籤看起來，確實有使用 GPU\n",
    "\n",
    "ws = WS(\"./data\", disable_cuda=False)\n",
    "pos = POS(\"./data\", disable_cuda=False)\n",
    "ner = NER(\"./data\", disable_cuda=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c436454-555b-47e8-aa2b-2973cd18849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 簡繁轉換器 (暫時用不到)\n",
    "# import opencc\n",
    "# converter = opencc.OpenCC('t2s.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace9c05f-db18-4bf0-985a-6ccefd5ec8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "start_time = time.time()\n",
    "print(f'[現在時間] {time.strftime(\"%Y-%m-%d %H:%M:%S\")}')\n",
    "\n",
    "source_file = os.path.join(\n",
    "        'C:\\\\', '課程', '交大','論文','案件整理',\n",
    "        'json_files_R.txt'\n",
    "        )\n",
    "    \n",
    "count_file_done_num = 0\n",
    "clear_output()\n",
    "\n",
    "# 多工時使用\n",
    "skip = 0 # 要跳過從第幾開始\n",
    "\n",
    "print('-'*50)\n",
    "print(f'>>開始分析...')\n",
    "print(f'[當前已分析數量] {count_file_done_num}')\n",
    "\n",
    "with open(source_file, 'r', encoding='utf-8') as f:\n",
    "    # 2022~2023年判決書有211萬7,454個json檔\n",
    "    # 故一次讀一個處理，減少記憶體占用\n",
    "    raw_data = ''\n",
    "    \n",
    "    while 1: \n",
    "        # 開始逐案讀取資料分析\n",
    "        file = f.readline()\n",
    "        count_file_done_num += 1\n",
    "        \n",
    "        if '刑事' in file:\n",
    "            # 篩掉一些比較非刑案的\n",
    "            if not ('簡易' in file or '民事' in file or '補償' in file or '憲法' in file or '商業' in file):\n",
    "                # 開始讀取裁判書內容\n",
    "                file = file.strip()\n",
    "\n",
    "                # 顯示進度\n",
    "                temp_time = time.time()\n",
    "                elapsed_time = temp_time - start_time\n",
    "                hours = int(elapsed_time // 3600)  # 計算小時數\n",
    "                minutes = int((elapsed_time % 3600) // 60)  # 計算分鐘數\n",
    "                seconds = int(elapsed_time % 60)  # 計算剩餘秒數\n",
    "                \n",
    "                clear_output()\n",
    "                print('-'*50)\n",
    "                print(f'>>開始分析...')\n",
    "                print(f'[當前已分析數量] {count_file_done_num}')\n",
    "                print(f'[累計耗時] {hours}:{minutes}:{seconds}')\n",
    "                print(f'[當前檔案] {file}')\n",
    "                \n",
    "                # 確定 file 存在\n",
    "                if not os.path.isfile(file):\n",
    "                    print(f'[並非正常檔案] 跳過...')\n",
    "                    time.sleep(1)\n",
    "                    continue\n",
    "                \n",
    "                try:\n",
    "                    with open(file, 'r', encoding='utf-8') as jf:\n",
    "                        json_data = json.load(jf)\n",
    "                except:\n",
    "                    x = traceback.format_exc()\n",
    "                    print(x)\n",
    "                    time.sleep(3)\n",
    "                    continue\n",
    "                    \n",
    "                # 資料清洗\n",
    "                parser = Judicial_Parser(json_data)\n",
    "                \n",
    "                jid = parser.jid.strip().replace(' ', '')\n",
    "                date = parser.dateSTR.strip().replace(' ', '')\n",
    "                raw = parser.raw\n",
    "                text = parser.text\n",
    "                text_u = parser.text_u\n",
    "                \n",
    "                # 確定是否已經在資料庫內\n",
    "                check_res = cur_POS.execute(f\"SELECT jid FROM results WHERE jid='{jid}'\")\n",
    "                temp = check_res.fetchone()\n",
    "                if temp:\n",
    "                    print(f'[JID] {jid}')\n",
    "                    print('>>此JID發現資料庫已有，跳過')\n",
    "                    continue\n",
    "                    \n",
    "                print('-'*50)\n",
    "                print(text_u[:1000])\n",
    "                print('-'*50)\n",
    "                \n",
    "                # 沒有在資料庫內才處理\n",
    "                \n",
    "                '''\n",
    "                ------------------------------------------------------------------\n",
    "                RE 擷取\n",
    "                ------------------------------------------------------------------\n",
    "                '''\n",
    "                 # Input text\n",
    "                print('[RE] 分析中')\n",
    "                # 擷取 RE 結果\n",
    "                re_dict = dict()\n",
    "                for re_type, re_func in re_extractors.items():\n",
    "                    re_temp_result = re_func(text_u)\n",
    "                    if re_temp_result:\n",
    "                        re_dict[re_type] = re_temp_result\n",
    "                    print(f'>> [{re_type}] {re_temp_result}')\n",
    "                \n",
    "                '''\n",
    "                ------------------------------------------------------------------\n",
    "                POS & NER 擷取\n",
    "                ------------------------------------------------------------------\n",
    "                '''\n",
    "                # Input text\n",
    "                print('-'*50)\n",
    "                print('[WS] 分析中')\n",
    "                sentence_list = text_u.split('。')\n",
    "                word_sentence_list = ws(\n",
    "                    sentence_list,\n",
    "                    # sentence_segmentation = True, # To consider delimiters\n",
    "                    # segment_delimiter_set = {\",\", \"。\", \":\", \"?\", \"!\", \";\"}), # This is the defualt set of delimiters\n",
    "                    # recommend_dictionary = dictionary1, # words in this dictionary are encouraged\n",
    "                    # coerce_dictionary = dictionary2, # words in this dictionary are forced\n",
    "                )\n",
    "                print('[POS] 分析中')\n",
    "                pos_sentence_list = pos(word_sentence_list)\n",
    "                print('[NER] 分析中')\n",
    "                entity_sentence_list = ner(word_sentence_list, pos_sentence_list)\n",
    "                \n",
    "                # 整理 POS 結果\n",
    "                pos_dict = dict()\n",
    "                for idx, words in enumerate(word_sentence_list):\n",
    "                    for idx2, word in enumerate(words):\n",
    "                        temp_type = pos_sentence_list[idx][idx2]\n",
    "                        word = word.strip().replace(' ', '').replace(':', '').replace(',', '')\n",
    "                        pos_dict.setdefault(temp_type, set())\n",
    "                        pos_dict[temp_type].add(word)\n",
    "                \n",
    "                # 擷取 NER 結果\n",
    "                ner_dict = dict()\n",
    "                for e in entity_sentence_list:\n",
    "                    for ee in e:\n",
    "                        ner_type = ee[2]\n",
    "                        ner_dict.setdefault(ner_type, set())\n",
    "                        temp_ner_result = ee[3].strip().replace(' ', '').replace(':', '').replace(',', '')\n",
    "                        ner_dict[ner_type].add(temp_ner_result)\n",
    "                print('-'*50)\n",
    "                \n",
    "                '''\n",
    "                ------------------------------------------------------------------\n",
    "                寫入 DB Table\n",
    "                ------------------------------------------------------------------\n",
    "                '''\n",
    "                print('-'*50)\n",
    "                print('>>準備寫入 RE 結果')\n",
    "                for re_type, re_keywords in re_dict.items():\n",
    "                    values_str = ','.join(re_keywords)\n",
    "                    to_db_content = \"INSERT INTO results VALUES(?, ?, ?, ?)\" # ? 是一個參數占位符，代表將要插入的值。\n",
    "                    cur_RE.execute(to_db_content, (jid, date, re_type, values_str))\n",
    "                con_RE.commit()\n",
    "                \n",
    "                print('-'*50)\n",
    "                print('>>準備寫入 POS 結果')\n",
    "                for temp_type, temp_keywords in pos_dict.items():\n",
    "                    temp_keywords = {tk.strip().replace(' ', '').replace(',', '').replace(':', '') for tk in temp_keywords if len(tk.strip().replace(' ', '').replace(',', '').replace(':', '')) > 1}\n",
    "                    temp_keywords = list(temp_keywords)\n",
    "                    temp_keywords.sort()\n",
    "                    values_str = ','.join(temp_keywords)\n",
    "                    to_db_content = \"INSERT INTO results VALUES(?, ?, ?, ?)\" # ? 是一個參數占位符，代表將要插入的值。\n",
    "                    cur_POS.execute(to_db_content, (jid, date, re_type, values_str))\n",
    "                con_POS.commit()\n",
    "                \n",
    "                print('-'*50)\n",
    "                print('>>準備寫入 NER 結果')\n",
    "                for temp_type, temp_keywords in ner_dict.items():\n",
    "                    temp_keywords = {tk.strip().replace(' ', '').replace(',', '').replace(':', '') for tk in temp_keywords if len(tk.strip().replace(' ', '').replace(',', '').replace(':', '')) > 1}\n",
    "                    temp_keywords = list(temp_keywords)\n",
    "                    temp_keywords.sort()\n",
    "                    values_str = ','.join(temp_keywords)\n",
    "                    to_db_content = \"INSERT INTO results VALUES(?, ?, ?, ?)\" # ? 是一個參數占位符，代表將要插入的值。\n",
    "                    cur_NER.execute(to_db_content, (jid, date, re_type, values_str))\n",
    "                con_NER.commit()\n",
    "                \n",
    "                print('-'*50)\n",
    "                print('>>完成!!!')\n",
    "\n",
    "                \n",
    "# 關閉 DB占用\n",
    "con_RE.close()\n",
    "con_POS.close()\n",
    "con_NER.close()\n",
    "\n",
    "# 顯示統計結果\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "hours = int(elapsed_time // 3600)  # 計算小時數\n",
    "minutes = int((elapsed_time % 3600) // 60)  # 計算分鐘數\n",
    "seconds = int(elapsed_time % 60)  # 計算剩餘秒數\n",
    "print(f'[累計耗時] {hours}:{minutes}:{seconds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29970839-c556-4499-a031-0a7239cb96d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
